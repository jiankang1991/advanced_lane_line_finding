{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.html import widgets\n",
    "from IPython.html.widgets import interact\n",
    "from IPython.display import display\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_cal(cal_dir, nx, ny):\n",
    "    \"\"\" camera calibration based on multiple chessboard images\n",
    "    https://docs.opencv.org/3.4.3/dc/dbb/tutorial_py_calibration.html\n",
    "    input:\n",
    "        cal_dir: input image directory \n",
    "        nx: number of corners in a row \n",
    "        ny: number of corners in a column\n",
    "\n",
    "    return:\n",
    "        mtx: camera matrix\n",
    "        dist: distortion coefficients\n",
    "\n",
    "    \"\"\"\n",
    "    img_paths = glob(cal_dir + '/calibration*.jpg')\n",
    "\n",
    "    # print(img_paths)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    objp = np.zeros((nx * ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "        if ret == True:\n",
    "            cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # cv2.imshow('img', img)\n",
    "            # cv2.waitKey(500)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    return (ret, mtx, dist, rvecs, tvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hls_thres_L(img, thresh=(0, 255)):\n",
    "    \"\"\" thresholding based on L channel value of HLS image \n",
    "    Input:\n",
    "        img: BGR image read by cv2\n",
    "        thresh: low and upper thresholds for values of L channel\n",
    "    Output:\n",
    "        binary_output: binary map of preserved values in-between the thresholds\n",
    "    \"\"\"\n",
    "    img_HLS = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    L_channel = img_HLS[...,-2]\n",
    "    binary_output = np.zeros_like(L_channel)\n",
    "    binary_output[(L_channel>thresh[0])&(L_channel<=thresh[1])] = 1\n",
    "    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hls_thres_S(img, thresh=(0, 255)):\n",
    "    \"\"\" thresholding based on S channel value of HLS image \n",
    "    Input:\n",
    "        img: BGR image read by cv2\n",
    "        thresh: low and upper thresholds for values of S channel\n",
    "    Output:\n",
    "        binary_output: binary map of preserved values in-between the thresholds\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    img_HLS = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    S_channel = img_HLS[...,-1]\n",
    "    binary_output = np.zeros_like(S_channel)\n",
    "    binary_output[(S_channel>thresh[0])&(S_channel<=thresh[1])] = 1\n",
    "    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \"\"\" thresholding method based on direction of derivatives\n",
    "    Input: \n",
    "        image: BGR image read by cv2\n",
    "        sobel_kernel: size of sobel kernel\n",
    "        thresh: low and upper thresholds for direction of derivatives\n",
    "    Output:\n",
    "        binary_output: binary map of preserved values in-between the thresholds\n",
    "    \"\"\"\n",
    "\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_gray_x_deriv = np.absolute(cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    img_gray_y_deriv = np.absolute(cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    \n",
    "    grad_dir = np.arctan2(img_gray_y_deriv, img_gray_x_deriv)\n",
    "    \n",
    "    binary_output = np.zeros_like(grad_dir)\n",
    "    \n",
    "    binary_output[(grad_dir>thresh[0])&(grad_dir<thresh[1])] = 1\n",
    "    \n",
    "\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \"\"\" thresholding method absed on magnitude of derivatives\n",
    "    Input:\n",
    "        image: BGR image read by cv2\n",
    "        sobel_kernel: size of sobel kernel\n",
    "        mag_thresh: low and upper thresholds for magnitudes of derivatives\n",
    "    Output:\n",
    "        binary_output: binary map of preserved values in-between the thresholds\n",
    "    \"\"\"\n",
    "\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_gray_x_deriv = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    img_gray_y_deriv = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    img_gray_xy_deriv = np.sqrt(img_gray_x_deriv**2 + img_gray_y_deriv**2)\n",
    "    \n",
    "    img_gray_xy_deriv = np.uint8(255*np.absolute(img_gray_xy_deriv)/np.max(np.absolute(img_gray_xy_deriv)))\n",
    "    \n",
    "    binary_output = np.zeros_like(img_gray_xy_deriv)\n",
    "    \n",
    "    \n",
    "    binary_output[(img_gray_xy_deriv>mag_thresh[0])&(img_gray_xy_deriv<mag_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_binary_mask(image, ksize, mag_low, mag_high, dir_low, dir_high, hls_low, hls_high, bright_low, bright_high):\n",
    "    \n",
    "    S_bin = hls_thres_S(image, (hls_low, hls_high))\n",
    "    L_bin = hls_thres_L(image, (bright_low, bright_high))\n",
    "    mag_bin = mag_thresh(image, ksize, (mag_low, mag_high))\n",
    "    dir_bin = dir_threshold(image, ksize, (dir_low, dir_high))\n",
    "    \n",
    "    combined = np.zeros_like(S_bin)\n",
    "    \n",
    "    S_ = S_bin == 1\n",
    "    L_ = L_bin == 1\n",
    "    mag_ = mag_bin == 1\n",
    "    dir_ = dir_bin == 1\n",
    "    \n",
    "    combined[(S_ | L_) & (mag_ & dir_)] = 1\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_mask(ksize, mag_low, mag_high, dir_low, dir_high, hls_low, hls_high, bright_low, bright_high):\n",
    "    combined = combined_binary_mask(image, ksize, mag_low, mag_high, dir_low, dir_high,\\\n",
    "                                    hls_low, hls_high, bright_low, bright_high)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(combined,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26653c55037849d59f1a9578aa4923a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='ksize', max=31, min=1, step=2), IntSlider(value=127, deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interactive_mask(ksize, mag_low, mag_high, dir_low, dir_high, hls_low, hls_high, bright_low, bright_high)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image_path = './challenge_images/image_140.png'\n",
    "\n",
    "img_dir = './camera_cal'\n",
    "\n",
    "_, mtx, dist, _, _ = camera_cal(img_dir, nx=9, ny=6)\n",
    "    \n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "\n",
    "\n",
    "interact(interactive_mask, ksize=(1,31,2), mag_low=(0,255), mag_high=(0,255),\\\n",
    "         dir_low=(0, np.pi/2), dir_high=(0, np.pi/2), hls_low=(0,255),\\\n",
    "         hls_high=(0,255), bright_low=(0,255), bright_high=(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
